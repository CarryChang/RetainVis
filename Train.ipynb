{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim,nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import time\n",
    "from models.data_loader import DataLoader\n",
    "from models.retain_bidirectional import RETAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=3\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "epochs = 30\n",
    "batch_size = 50\n",
    "max_seq_length = 100\n",
    "min_seq_length = 5\n",
    "num_classes = 268\n",
    "emb_size = 128\n",
    "hid_size = 128\n",
    "lr = 0.001\n",
    "cuda_flag = True\n",
    "\n",
    "# data loader\n",
    "D = DataLoader(batch_size=batch_size,\n",
    "   data_dir='data/batches/',\n",
    "    mode='train', max_seq_length=max_seq_length, min_seq_length=min_seq_length)\n",
    "\n",
    "# import model and optimization settings\n",
    "model = RETAIN(emb_size,hid_size,num_classes,cuda_flag)\n",
    "model.release = True\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "cnt = 0\n",
    "if cuda_flag:\n",
    "    model.cuda()\n",
    "    criterion.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train model\n",
    "lr_list = [0.001, 0.0003, 0.0001, 0.00003, 0.00001, 0.000003, 0.000001]\n",
    "lr_counter = 0\n",
    "lr = lr_list[lr_counter]\n",
    "opt = optim.Adam(model.parameters(), lr=lr)\n",
    "loss_list = []\n",
    "loss_mean = 0.0\n",
    "file_cnt = 0\n",
    "cnt = 0\n",
    "loss_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 [0, 0/206] - opening file 2014_94.pckl\n",
      "Loss: 5.557\n",
      "Epoch 0 [1, 1/206] - opening file 2014_216.pckl\n",
      "Loss: 5.331\n",
      "Epoch 0 [2, 2/206] - opening file 2014_213.pckl\n",
      "Loss: 5.187\n",
      "Epoch 0 [3, 3/206] - opening file 2014_254.pckl\n",
      "Loss: 4.792\n",
      "Epoch 0 [4, 4/206] - opening file 2014_192.pckl\n",
      "Loss: 4.995\n",
      "Epoch 0 [5, 5/206] - opening file 2014_287.pckl\n",
      "Loss: 4.864\n",
      "Epoch 0 [6, 6/206] - opening file 2014_34.pckl\n",
      "[10] 5.191\n",
      "Loss: 5.137\n",
      "Epoch 0 [7, 7/206] - opening file 2014_138.pckl\n",
      "Loss: 3.568\n",
      "Epoch 0 [8, 8/206] - opening file 2014_172.pckl\n",
      "Loss: 3.799\n",
      "Epoch 0 [9, 9/206] - opening file 2014_194.pckl\n",
      "Loss: 3.460\n",
      "Epoch 0 [10, 10/206] - opening file 2014_252.pckl\n",
      "Loss: 2.906\n",
      "Epoch 0 [11, 11/206] - opening file 2014_261.pckl\n",
      "Loss: 3.133\n",
      "Epoch 0 [12, 12/206] - opening file 2014_54.pckl\n",
      "[20] 4.363\n",
      "Loss: 4.319\n",
      "Epoch 0 [13, 13/206] - opening file 2014_132.pckl\n",
      "Loss: 3.574\n",
      "Epoch 0 [14, 14/206] - opening file 2014_116.pckl\n",
      "Loss: 3.944\n",
      "Epoch 0 [15, 15/206] - opening file 2014_285.pckl\n",
      "Loss: 3.823\n",
      "Epoch 0 [16, 16/206] - opening file 2014_91.pckl\n",
      "Loss: 4.158\n",
      "Epoch 0 [17, 17/206] - opening file 2014_109.pckl\n",
      "Loss: 4.057\n",
      "Epoch 0 [18, 18/206] - opening file 2014_271.pckl\n",
      "Loss: 4.489\n",
      "Epoch 0 [19, 19/206] - opening file 2014_145.pckl\n",
      "Loss: 3.564\n",
      "Epoch 0 [20, 20/206] - opening file 2014_288.pckl\n",
      "Loss: 1.956\n",
      "Epoch 0 [21, 21/206] - opening file 2014_41.pckl\n",
      "[30] 4.485\n",
      "Loss: 4.400\n",
      "Epoch 0 [22, 22/206] - opening file 2014_68.pckl\n",
      "Loss: 3.965\n",
      "Epoch 0 [23, 23/206] - opening file 2014_225.pckl\n",
      "Loss: 3.918\n",
      "Epoch 0 [24, 24/206] - opening file 2014_236.pckl\n",
      "Loss: 3.482\n",
      "Epoch 0 [25, 25/206] - opening file 2014_102.pckl\n",
      "Loss: 3.688\n",
      "Epoch 0 [26, 26/206] - opening file 2014_168.pckl\n",
      "[40] 3.072\n",
      "Loss: 3.072\n",
      "Epoch 0 [27, 27/206] - opening file 2014_127.pckl\n",
      "Loss: 3.651\n",
      "Epoch 0 [28, 28/206] - opening file 2014_262.pckl\n",
      "Loss: 1.566\n",
      "Epoch 0 [29, 29/206] - opening file 2014_202.pckl\n",
      "Loss: 3.307\n",
      "Epoch 0 [30, 30/206] - opening file 2014_53.pckl\n",
      "Loss: 3.742\n",
      "Epoch 0 [31, 31/206] - opening file 2014_140.pckl\n",
      "Loss: 3.767\n",
      "Epoch 0 [32, 32/206] - opening file 2014_129.pckl\n",
      "Loss: 4.028\n",
      "Epoch 0 [33, 33/206] - opening file 2014_121.pckl\n",
      "Loss: 3.417\n",
      "Epoch 0 [34, 34/206] - opening file 2014_284.pckl\n",
      "[50] 2.546\n",
      "Loss: 2.546\n",
      "Epoch 0 [35, 35/206] - opening file 2014_19.pckl\n"
     ]
    }
   ],
   "source": [
    "len_train = len(D.train_list)\n",
    "while file_cnt<(epochs*len(D.train_list)):\n",
    "    idx = file_cnt%(len_train)\n",
    "    file = D.train_list[idx]\n",
    "    if file not in loss_dict:\n",
    "        loss_dict[file] = []\n",
    "    print(\"Epoch %d [%d, %d/%d] - opening file %s\" %(((file_cnt+1)/len_train), file_cnt, idx, len_train, D.train_list[idx]))\n",
    "    file_num = int(file.split('_')[1].split('.')[0])\n",
    "    D.batch_size = int(40000/file_num)\n",
    "    D.load_batch_file(file)\n",
    "    loss_list = []\n",
    "    for i in range(D.batch_count):\n",
    "        cnt+=1\n",
    "        input_list, targets = D.get_batch()\n",
    "        start = time.time()\n",
    "        inputs = model.list_to_tensor(input_list)\n",
    "        outputs = model(inputs)\n",
    "        targets = Variable(torch.LongTensor(targets)[:,-1]) # to only use last of each sequence\n",
    "#             targets = Variable(torch.LongTensor(targets)).view(len(inputs),-1)[:,-1] # to only use last of each sequence\n",
    "        if cuda_flag:\n",
    "            targets = targets.cuda()\n",
    "        loss = criterion(outputs.view(-1,num_classes),targets)\n",
    "        loss_list.append(loss.data[0])\n",
    "        if cnt%10==0:\n",
    "            print('[%d] %1.3f' %(cnt,loss.data[0]))\n",
    "        if cnt%500==0:\n",
    "            print(\"Saving model at %dth step\" %cnt)\n",
    "            torch.save(model,'data/saved_weights/retain_bi_%d.pth'%(cnt))\n",
    "            # create CPU version\n",
    "            model2 = RETAIN(emb_size,hid_size,num_classes,False)\n",
    "            if cuda_flag:\n",
    "                model.cpu()\n",
    "            model2.load_state_dict(model.state_dict())\n",
    "            torch.save(model2,'data/saved_weights/retain_bi_%d_cpu.pth'%(cnt))\n",
    "            if cuda_flag:\n",
    "                model.cuda()\n",
    "            print(\"Saving at %dth step\"%cnt)\n",
    "        # manual loss changes\n",
    "        if cnt==100:\n",
    "            lr_counter+=1\n",
    "            lr = lr_list[lr_counter]\n",
    "            opt = optim.Adam(model.parameters(),lr=lr)\n",
    "        if cnt==500:\n",
    "            lr_counter+=1\n",
    "            lr = lr_list[lr_counter]\n",
    "            opt = optim.Adam(model.parameters(),lr=lr)        \n",
    "        if loss.data[0]>10:\n",
    "            import sys\n",
    "            sys.exit()\n",
    "#             print(loss.data[0])\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    print(\"Loss: %1.3f\" %np.mean(loss_list))\n",
    "    loss_dict[file].append(loss.data[0])\n",
    "    file_cnt+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lower learning rate\n",
    "lr_counter+=1\n",
    "lr = lr_list[lr_counter]\n",
    "opt = optim.Adam(model.parameters(), lr=lr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
