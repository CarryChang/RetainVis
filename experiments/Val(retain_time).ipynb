{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim,nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "os.chdir('..')\n",
    "from models.data_loader import DataLoader\n",
    "from models.retain_time import RETAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "batch_size = 50\n",
    "max_seq_length = 300\n",
    "min_seq_length = 5\n",
    "emb_size = 128\n",
    "hid_size = 128\n",
    "num_classes = 267+1\n",
    "cuda_flag = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data loader\n",
    "D = DataLoader(batch_size=batch_size,\n",
    "   data_dir='data/batches/',\n",
    "    mode='val', max_seq_length=max_seq_length, min_seq_length=min_seq_length)\n",
    "\n",
    "# load model\n",
    "model = RETAIN(emb_size,hid_size,num_classes,cuda_flag)\n",
    "if cuda_flag:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num in np.arange(500,15000,500):\n",
    "    if cuda_flag:\n",
    "        ver = 'retain_time_%d.pth'%num\n",
    "    else:\n",
    "        ver = 'retain_bi_%d_cpu.pth'%num\n",
    "    model.load_state_dict(torch.load(os.path.join('data/saved_weights',ver)))\n",
    "    model.eval()\n",
    "    # test model\n",
    "    cnt = 0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    correct_5 = 0\n",
    "    \n",
    "    for i,file in enumerate(D.val_list):\n",
    "        file_num = int(file.split('_')[1].split('.')[0])\n",
    "        D.batch_size = int(20000/file_num)\n",
    "        D.load_batch_file(file)\n",
    "        for i in range(D.batch_count):\n",
    "            cnt+=1\n",
    "            input_list, targets, dates = D.get_batch()\n",
    "            dates = Variable(torch.Tensor(dates), requires_grad=False)\n",
    "            if cuda_flag:\n",
    "                dates = dates.cuda()\n",
    "            inputs = model.list_to_tensor(input_list)\n",
    "            outputs = model(inputs,dates)\n",
    "            targets = torch.LongTensor(targets).view(len(inputs),-1)[:,-1] # to only use last of each sequence\n",
    "            \n",
    "#             print(type(targets))\n",
    "            if cuda_flag:\n",
    "                targets = targets.cuda()\n",
    "            total+=len(inputs)\n",
    "            targets = targets.tolist()\n",
    "            for tup in zip(targets,outputs.topk(5)[1].data.tolist()):\n",
    "                if tup[0]==tup[1][0]:\n",
    "                    correct +=1\n",
    "                if tup[0] in tup[1]:\n",
    "                    correct_5 +=1\n",
    "    print(ver)\n",
    "    print(\"Top-1 accuracy: %d/%d = %1.3f\"%(correct,total,correct*1.0/total))\n",
    "    print(\"Top-5 accuracy: %d/%d = %1.3f\"%(correct_5,total,correct_5*1.0/total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
