{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pickle\n",
    "import os\n",
    "os.chdir('/home/mjc/github/EHRVis/')\n",
    "with open('data/batches/val/2014_104.pckl','rb') as f:\n",
    "    samples = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn,optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "from functions import date_converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.curdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Variable(torch.Tensor(100,50,128).normal_())\n",
    "# inputs = Variable(torch.Tensor(100,100,128).normal_().cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try opening custom RNN\n",
    "from models.time_rnn import rnn_base, rnn_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "out = date_converter(20140131)\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Test(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Test,self).__init__()\n",
    "        self.hidden_size = 128\n",
    "        self.input_size = 128\n",
    "        self.output_size = 268\n",
    "    \n",
    "        self.RNN1 = nn.LSTM(hidden_size=self.hidden_size, input_size=self.input_size, bias=False, batch_first=True)\n",
    "        self.RNN2 = rnn_base.LSTM(hidden_size=self.hidden_size, input_size=self.input_size, bias=False, batch_first=True)\n",
    "        self.RNN3 = nn.LSTMCell(hidden_size=self.hidden_size, input_size=self.input_size, bias=False)\n",
    "        self.RNN4 = rnn_base.LSTMCell_time(hidden_size=self.hidden_size, input_size=self.input_size, bias=False)\n",
    "        \n",
    "    def forward(self,inputs):\n",
    "        start = time.time()\n",
    "        b, seq, hid = inputs.size()\n",
    "\n",
    "        start = time.time()\n",
    "        hid1, cell1 = self.RNN1(inputs)[1]\n",
    "        print(\"Method 1\")\n",
    "        print(time.time()-start)\n",
    "        start = time.time()\n",
    "        hid2, cell2 = self.RNN2(inputs)[1]\n",
    "        print(\"Method 2\")\n",
    "        print(time.time()-start)\n",
    "        start = time.time()\n",
    "        hid3 = Variable(torch.randn(b,hid).normal_())\n",
    "        cell3 = Variable(torch.Tensor(b,hid).normal_())\n",
    "        for i in range(seq):\n",
    "            hid3, cell3 = self.RNN3(inputs[:,i,:],(hid3,cell3))\n",
    "        print(\"Method 3\")\n",
    "        print(time.time()-start)\n",
    "\n",
    "        start = time.time()\n",
    "        hid4 = Variable(torch.randn(b,hid).normal_())\n",
    "        cell4 = Variable(torch.Tensor(b,hid).normal_())\n",
    "        for i in range(seq):\n",
    "            hid4, cell4 = self.RNN3(inputs[:,i,:],(hid4,cell4))\n",
    "        print(\"Method 4\")\n",
    "        print(time.time()-start)\n",
    "#         return ((hid3,cell3),(hid4,cell4))\n",
    "#         return ((hid1,cell1),(hid2,cell2),(hid3,cell3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Test(\n",
       "  (RNN1): LSTM(128, 128, bias=False, batch_first=True)\n",
       "  (RNN2): LSTM(128, 128, bias=False, batch_first=True)\n",
       "  (RNN3): LSTMCell(128, 128, bias=False)\n",
       "  (RNN4): LSTMCell_time(128, 128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test= Test()\n",
    "test.cpu()\n",
    "# test.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method 1\n",
      "0.14815497398376465\n",
      "([[Parameter containing:\n",
      "-8.5452e-02 -2.1052e-02  8.7528e-02  ...  -3.7807e-02  7.6631e-02  4.2297e-02\n",
      " 3.2834e-02  7.2931e-02 -8.2386e-02  ...   8.2221e-03 -6.0625e-02 -6.9933e-02\n",
      "-8.2728e-02  8.3201e-02  7.2076e-02  ...   1.4865e-02  6.1393e-02 -1.5973e-02\n",
      "                ...                   ⋱                   ...                \n",
      "-5.6404e-02  6.8817e-02 -2.2709e-02  ...  -2.7402e-02 -5.0894e-03 -4.9341e-02\n",
      " 5.8236e-02  7.0276e-03  7.8666e-02  ...   1.5080e-03  5.0784e-02  6.2848e-02\n",
      "-9.3417e-03 -6.5837e-02 -5.0387e-02  ...  -1.4167e-02 -3.3260e-02 -5.7781e-02\n",
      "[torch.FloatTensor of size 512x128]\n",
      ", Parameter containing:\n",
      "1.00000e-02 *\n",
      " 7.1524 -0.2093 -4.0871  ...   7.0079 -0.9767 -4.0853\n",
      " 8.5470 -7.4804 -7.5928  ...  -7.1755 -0.8471  8.4880\n",
      " 6.6776 -0.8398 -5.5200  ...   8.7501  2.5887 -0.4949\n",
      "          ...             ⋱             ...          \n",
      " 5.6955 -1.0198 -4.2755  ...   7.5038  6.7103  5.8915\n",
      " 5.8921 -8.8312  6.1982  ...   1.8603  8.0238  3.1309\n",
      " 6.2340 -2.2265 -8.8269  ...   4.4314 -1.3281  4.4531\n",
      "[torch.FloatTensor of size 512x128]\n",
      "]], (Variable containing:\n",
      "( 0 ,.,.) = \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "     ...       ⋱       ...    \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "[torch.FloatTensor of size 1x100x128]\n",
      ", Variable containing:\n",
      "( 0 ,.,.) = \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "     ...       ⋱       ...    \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "[torch.FloatTensor of size 1x100x128]\n",
      "), None) {}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "LSTMCell_time() missing 2 required positional arguments: 'w_hh' and 'w_d'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-0d623169be45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-a3859ecc02d1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mhid2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRNN2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Method 2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/EHRVis/models/time_rnn/rnn_base.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;31m#     flat_weight=flat_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;31m# )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/EHRVis/models/time_rnn/rnn_functions.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, *fargs, **fkwargs)\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/EHRVis/models/time_rnn/rnn_functions.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, weight, hidden)\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0mnexth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_first\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/EHRVis/models/time_rnn/rnn_functions.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, hidden, weight)\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_directions\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m                 \u001b[0mhy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m                 \u001b[0mnext_hidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0mall_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/EHRVis/models/time_rnn/rnn_functions.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, hidden, weight)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreverse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m             \u001b[0;31m# hack to handle LSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: LSTMCell_time() missing 2 required positional arguments: 'w_hh' and 'w_d'"
     ]
    }
   ],
   "source": [
    "test(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. w/ cuda\n",
    "  1. 0.14, 0.0003~0.001 for each iter\n",
    "  2. 0.006\n",
    "2. w/o cuda\n",
    "  1. 0.09~0.2\n",
    "  2. 0.09~0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class LSTMCell in module torch.nn.modules.rnn:\n",
      "\n",
      "class LSTMCell(RNNCellBase)\n",
      " |  A long short-term memory (LSTM) cell.\n",
      " |  \n",
      " |  .. math::\n",
      " |  \n",
      " |      \\begin{array}{ll}\n",
      " |      i = \\mathrm{sigmoid}(W_{ii} x + b_{ii} + W_{hi} h + b_{hi}) \\\\\n",
      " |      f = \\mathrm{sigmoid}(W_{if} x + b_{if} + W_{hf} h + b_{hf}) \\\\\n",
      " |      g = \\tanh(W_{ig} x + b_{ig} + W_{hc} h + b_{hg}) \\\\\n",
      " |      o = \\mathrm{sigmoid}(W_{io} x + b_{io} + W_{ho} h + b_{ho}) \\\\\n",
      " |      c' = f * c + i * g \\\\\n",
      " |      h' = o * \\tanh(c') \\\\\n",
      " |      \\end{array}\n",
      " |  \n",
      " |  Args:\n",
      " |      input_size: The number of expected features in the input x\n",
      " |      hidden_size: The number of features in the hidden state h\n",
      " |      bias: If `False`, then the layer does not use bias weights `b_ih` and\n",
      " |          `b_hh`. Default: ``True``\n",
      " |  \n",
      " |  Inputs: input, (h_0, c_0)\n",
      " |      - **input** (batch, input_size): tensor containing input features\n",
      " |      - **h_0** (batch, hidden_size): tensor containing the initial hidden\n",
      " |        state for each element in the batch.\n",
      " |      - **c_0** (batch. hidden_size): tensor containing the initial cell state\n",
      " |        for each element in the batch.\n",
      " |  \n",
      " |  Outputs: h_1, c_1\n",
      " |      - **h_1** (batch, hidden_size): tensor containing the next hidden state\n",
      " |        for each element in the batch\n",
      " |      - **c_1** (batch, hidden_size): tensor containing the next cell state\n",
      " |        for each element in the batch\n",
      " |  \n",
      " |  Attributes:\n",
      " |      weight_ih: the learnable input-hidden weights, of shape\n",
      " |          `(4*hidden_size x input_size)`\n",
      " |      weight_hh: the learnable hidden-hidden weights, of shape\n",
      " |          `(4*hidden_size x hidden_size)`\n",
      " |      bias_ih: the learnable input-hidden bias, of shape `(4*hidden_size)`\n",
      " |      bias_hh: the learnable hidden-hidden bias, of shape `(4*hidden_size)`\n",
      " |  \n",
      " |  Examples::\n",
      " |  \n",
      " |      >>> rnn = nn.LSTMCell(10, 20)\n",
      " |      >>> input = Variable(torch.randn(6, 3, 10))\n",
      " |      >>> hx = Variable(torch.randn(3, 20))\n",
      " |      >>> cx = Variable(torch.randn(3, 20))\n",
      " |      >>> output = []\n",
      " |      >>> for i in range(6):\n",
      " |      ...     hx, cx = rnn(input[i], (hx, cx))\n",
      " |      ...     output.append(hx)\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      LSTMCell\n",
      " |      RNNCellBase\n",
      " |      torch.nn.modules.module.Module\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, input_size, hidden_size, bias=True)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  forward(self, input, hx)\n",
      " |      Defines the computation performed at every call.\n",
      " |      \n",
      " |      Should be overriden by all subclasses.\n",
      " |      \n",
      " |      .. note::\n",
      " |          Although the recipe for forward pass needs to be defined within\n",
      " |          this function, one should call the :class:`Module` instance afterwards\n",
      " |          instead of this since the former takes care of running the\n",
      " |          registered hooks while the latter silently ignores them.\n",
      " |  \n",
      " |  reset_parameters(self)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from RNNCellBase:\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  __call__(self, *input, **kwargs)\n",
      " |      Call self as a function.\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __dir__(self)\n",
      " |      __dir__() -> list\n",
      " |      default dir() implementation\n",
      " |  \n",
      " |  __getattr__(self, name)\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Implement setattr(self, name, value).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  add_module(self, name, module)\n",
      " |      Adds a child module to the current module.\n",
      " |      \n",
      " |      The module can be accessed as an attribute using the given name.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (string): name of the child module. The child module can be\n",
      " |              accessed from this module using the given name\n",
      " |          parameter (Module): child module to be added to the module.\n",
      " |  \n",
      " |  apply(self, fn)\n",
      " |      Applies ``fn`` recursively to every submodule (as returned by ``.children()``)\n",
      " |      as well as self. Typical use includes initializing the parameters of a model\n",
      " |      (see also :ref:`torch-nn-init`).\n",
      " |      \n",
      " |      Args:\n",
      " |          fn (:class:`Module` -> None): function to be applied to each submodule\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |      \n",
      " |      Example:\n",
      " |          >>> def init_weights(m):\n",
      " |          >>>     print(m)\n",
      " |          >>>     if type(m) == nn.Linear:\n",
      " |          >>>         m.weight.data.fill_(1.0)\n",
      " |          >>>         print(m.weight)\n",
      " |          >>>\n",
      " |          >>> net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))\n",
      " |          >>> net.apply(init_weights)\n",
      " |          Linear (2 -> 2)\n",
      " |          Parameter containing:\n",
      " |           1  1\n",
      " |           1  1\n",
      " |          [torch.FloatTensor of size 2x2]\n",
      " |          Linear (2 -> 2)\n",
      " |          Parameter containing:\n",
      " |           1  1\n",
      " |           1  1\n",
      " |          [torch.FloatTensor of size 2x2]\n",
      " |          Sequential (\n",
      " |            (0): Linear (2 -> 2)\n",
      " |            (1): Linear (2 -> 2)\n",
      " |          )\n",
      " |  \n",
      " |  children(self)\n",
      " |      Returns an iterator over immediate children modules.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Module: a child module\n",
      " |  \n",
      " |  cpu(self)\n",
      " |      Moves all model parameters and buffers to the CPU.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  cuda(self, device=None)\n",
      " |      Moves all model parameters and buffers to the GPU.\n",
      " |      \n",
      " |      This also makes associated parameters and buffers different objects. So\n",
      " |      it should be called before constructing optimizer if the module will\n",
      " |      live on GPU while being optimized.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          device (int, optional): if specified, all parameters will be\n",
      " |              copied to that device\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  double(self)\n",
      " |      Casts all parameters and buffers to double datatype.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  eval(self)\n",
      " |      Sets the module in evaluation mode.\n",
      " |      \n",
      " |      This has any effect only on modules such as Dropout or BatchNorm.\n",
      " |  \n",
      " |  float(self)\n",
      " |      Casts all parameters and buffers to float datatype.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  half(self)\n",
      " |      Casts all parameters and buffers to half datatype.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  load_state_dict(self, state_dict, strict=True)\n",
      " |      Copies parameters and buffers from :attr:`state_dict` into\n",
      " |      this module and its descendants. If :attr:`strict` is ``True`` then\n",
      " |      the keys of :attr:`state_dict` must exactly match the keys returned\n",
      " |      by this module's :func:`state_dict()` function.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          state_dict (dict): A dict containing parameters and\n",
      " |              persistent buffers.\n",
      " |          strict (bool): Strictly enforce that the keys in :attr:`state_dict`\n",
      " |              match the keys returned by this module's `:func:`state_dict()`\n",
      " |              function.\n",
      " |  \n",
      " |  modules(self)\n",
      " |      Returns an iterator over all modules in the network.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Module: a module in the network\n",
      " |      \n",
      " |      Note:\n",
      " |          Duplicate modules are returned only once. In the following\n",
      " |          example, ``l`` will be returned only once.\n",
      " |      \n",
      " |          >>> l = nn.Linear(2, 2)\n",
      " |          >>> net = nn.Sequential(l, l)\n",
      " |          >>> for idx, m in enumerate(net.modules()):\n",
      " |          >>>     print(idx, '->', m)\n",
      " |          0 -> Sequential (\n",
      " |            (0): Linear (2 -> 2)\n",
      " |            (1): Linear (2 -> 2)\n",
      " |          )\n",
      " |          1 -> Linear (2 -> 2)\n",
      " |  \n",
      " |  named_children(self)\n",
      " |      Returns an iterator over immediate children modules, yielding both\n",
      " |      the name of the module as well as the module itself.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, Module): Tuple containing a name and child module\n",
      " |      \n",
      " |      Example:\n",
      " |          >>> for name, module in model.named_children():\n",
      " |          >>>     if name in ['conv4', 'conv5']:\n",
      " |          >>>         print(module)\n",
      " |  \n",
      " |  named_modules(self, memo=None, prefix='')\n",
      " |      Returns an iterator over all modules in the network, yielding\n",
      " |      both the name of the module as well as the module itself.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, Module): Tuple of name and module\n",
      " |      \n",
      " |      Note:\n",
      " |          Duplicate modules are returned only once. In the following\n",
      " |          example, ``l`` will be returned only once.\n",
      " |      \n",
      " |          >>> l = nn.Linear(2, 2)\n",
      " |          >>> net = nn.Sequential(l, l)\n",
      " |          >>> for idx, m in enumerate(net.named_modules()):\n",
      " |          >>>     print(idx, '->', m)\n",
      " |          0 -> ('', Sequential (\n",
      " |            (0): Linear (2 -> 2)\n",
      " |            (1): Linear (2 -> 2)\n",
      " |          ))\n",
      " |          1 -> ('0', Linear (2 -> 2))\n",
      " |  \n",
      " |  named_parameters(self, memo=None, prefix='')\n",
      " |      Returns an iterator over module parameters, yielding both the\n",
      " |      name of the parameter as well as the parameter itself\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, Parameter): Tuple containing the name and parameter\n",
      " |      \n",
      " |      Example:\n",
      " |          >>> for name, param in self.named_parameters():\n",
      " |          >>>    if name in ['bias']:\n",
      " |          >>>        print(param.size())\n",
      " |  \n",
      " |  parameters(self)\n",
      " |      Returns an iterator over module parameters.\n",
      " |      \n",
      " |      This is typically passed to an optimizer.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Parameter: module parameter\n",
      " |      \n",
      " |      Example:\n",
      " |          >>> for param in model.parameters():\n",
      " |          >>>     print(type(param.data), param.size())\n",
      " |          <class 'torch.FloatTensor'> (20L,)\n",
      " |          <class 'torch.FloatTensor'> (20L, 1L, 5L, 5L)\n",
      " |  \n",
      " |  register_backward_hook(self, hook)\n",
      " |      Registers a backward hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time the gradients with respect to module\n",
      " |      inputs are computed. The hook should have the following signature::\n",
      " |      \n",
      " |          hook(module, grad_input, grad_output) -> Tensor or None\n",
      " |      \n",
      " |      The :attr:`grad_input` and :attr:`grad_output` may be tuples if the\n",
      " |      module has multiple inputs or outputs. The hook should not modify its\n",
      " |      arguments, but it can optionally return a new gradient with respect to\n",
      " |      input that will be used in place of :attr:`grad_input` in subsequent\n",
      " |      computations.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_buffer(self, name, tensor)\n",
      " |      Adds a persistent buffer to the module.\n",
      " |      \n",
      " |      This is typically used to register a buffer that should not to be\n",
      " |      considered a model parameter. For example, BatchNorm's ``running_mean``\n",
      " |      is not a parameter, but is part of the persistent state.\n",
      " |      \n",
      " |      Buffers can be accessed as attributes using given names.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (string): name of the buffer. The buffer can be accessed\n",
      " |              from this module using the given name\n",
      " |          tensor (Tensor): buffer to be registered.\n",
      " |      \n",
      " |      Example:\n",
      " |          >>> self.register_buffer('running_mean', torch.zeros(num_features))\n",
      " |  \n",
      " |  register_forward_hook(self, hook)\n",
      " |      Registers a forward hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time after :func:`forward` has computed an output.\n",
      " |      It should have the following signature::\n",
      " |      \n",
      " |          hook(module, input, output) -> None\n",
      " |      \n",
      " |      The hook should not modify the input or output.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_forward_pre_hook(self, hook)\n",
      " |      Registers a forward pre-hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time before :func:`forward` is invoked.\n",
      " |      It should have the following signature::\n",
      " |      \n",
      " |          hook(module, input) -> None\n",
      " |      \n",
      " |      The hook should not modify the input.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_parameter(self, name, param)\n",
      " |      Adds a parameter to the module.\n",
      " |      \n",
      " |      The parameter can be accessed as an attribute using given name.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (string): name of the parameter. The parameter can be accessed\n",
      " |              from this module using the given name\n",
      " |          parameter (Parameter): parameter to be added to the module.\n",
      " |  \n",
      " |  share_memory(self)\n",
      " |  \n",
      " |  state_dict(self, destination=None, prefix='', keep_vars=False)\n",
      " |      Returns a dictionary containing a whole state of the module.\n",
      " |      \n",
      " |      Both parameters and persistent buffers (e.g. running averages) are\n",
      " |      included. Keys are corresponding parameter and buffer names.\n",
      " |      \n",
      " |      When keep_vars is ``True``, it returns a Variable for each parameter\n",
      " |      (rather than a Tensor).\n",
      " |      \n",
      " |      Args:\n",
      " |          destination (dict, optional):\n",
      " |              if not None, the return dictionary is stored into destination.\n",
      " |              Default: None\n",
      " |          prefix (string, optional): Adds a prefix to the key (name) of every\n",
      " |              parameter and buffer in the result dictionary. Default: ''\n",
      " |          keep_vars (bool, optional): if ``True``, returns a Variable for each\n",
      " |              parameter. If ``False``, returns a Tensor for each parameter.\n",
      " |              Default: ``False``\n",
      " |      \n",
      " |      Returns:\n",
      " |          dict:\n",
      " |              a dictionary containing a whole state of the module\n",
      " |      \n",
      " |      Example:\n",
      " |          >>> module.state_dict().keys()\n",
      " |          ['bias', 'weight']\n",
      " |  \n",
      " |  train(self, mode=True)\n",
      " |      Sets the module in training mode.\n",
      " |      \n",
      " |      This has any effect only on modules such as Dropout or BatchNorm.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  type(self, dst_type)\n",
      " |      Casts all parameters and buffers to dst_type.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          dst_type (type or string): the desired type\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  zero_grad(self)\n",
      " |      Sets gradients of all model parameters to zero.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  dump_patches = False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(nn.LSTMCell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cell = Variable(torch.randn(100,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.018282175064086914\n",
      "0.0058746337890625\n"
     ]
    }
   ],
   "source": [
    "x = Variable(torch.randn(100,128))\n",
    "h = Variable(torch.randn(100,128))\n",
    "\n",
    "# method 1\n",
    "start = time.time()\n",
    "W_all = nn.Linear(128,128*4)\n",
    "U_all = nn.Linear(128,128*4)\n",
    "f,i,o,c = torch.chunk(W_all(x)+U_all(h),4,1)\n",
    "print(time.time()-start)\n",
    "\n",
    "# method 2\n",
    "start = time.time()\n",
    "W_i = nn.Linear(128,128)\n",
    "W_f = nn.Linear(128,128)\n",
    "W_o = nn.Linear(128,128)\n",
    "W_c = nn.Linear(128,128)\n",
    "U_i = nn.Linear(128,128)\n",
    "U_f = nn.Linear(128,128)\n",
    "U_o = nn.Linear(128,128)\n",
    "U_c = nn.Linear(128,128)\n",
    "i = W_i(x)+U_i(h)\n",
    "o = W_o(x)+U_o(h)\n",
    "f = W_f(x)+U_f(h)\n",
    "c = W_c(x)+U_c(h)\n",
    "print(time.time()-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_list = []\n",
    "W = nn.Linear(4,4)\n",
    "hx = Variable(torch.randn(2,4))\n",
    "for i in range(5):\n",
    "    out_list.append(hx)\n",
    "    hx = W(hx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 128\n",
    "hidden_size = 128\n",
    "W_all = nn.Linear(input_size, hidden_size*4)\n",
    "U_all = nn.Linear(hidden_size, hidden_size*4, bias=False)\n",
    "W_d = nn.Linear(hidden_size, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1501924991607666\n"
     ]
    }
   ],
   "source": [
    "b = 500\n",
    "x = Variable(torch.randn(b,hidden_size), requires_grad=False)\n",
    "h = Variable(torch.randn(b,hidden_size), requires_grad=False)\n",
    "c = Variable(torch.randn(b,hidden_size), requires_grad=False)\n",
    "x = x.cpu()\n",
    "h = h.cpu()\n",
    "c = c.cpu()\n",
    "\n",
    "W_all.cuda()\n",
    "U_all.cuda()\n",
    "W_d.cuda()\n",
    "start = time.time()\n",
    "outputs = []\n",
    "x = x.cuda()\n",
    "h = h.cuda()\n",
    "c = c.cuda()\n",
    "for i in range(100):\n",
    "    c_s1 = F.tanh(W_d(c))\n",
    "    c_s2 = c_s1 * 0.36\n",
    "    c_l = c - c_s1\n",
    "    c_adj = c_l + c_s2\n",
    "    outs = W_all(h)+U_all(x)\n",
    "    f, i, o, c_tmp = torch.chunk(outs,4,1)\n",
    "    c = f*c_adj + i*c_tmp\n",
    "    h = o*F.tanh(c)\n",
    "    outputs.append(h)\n",
    "outputs = torch.stack(outputs,1)\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "( 0 ,.,.) = \n",
       " -3.4575e-01  2.0295e-01  6.5576e-04  ...  -5.4149e-01  5.6244e-01  1.7737e-01\n",
       " -8.3154e-02  7.5503e-01  1.7961e-02  ...   5.5867e-02 -1.3854e-02 -1.1016e-01\n",
       "  1.7480e-01  1.9724e-01 -1.6898e-03  ...  -4.5279e-02 -3.5027e-02  1.0929e-01\n",
       "                 ...                   ⋱                   ...                \n",
       " -8.9460e-04  5.0247e-01  1.8987e-03  ...   1.9689e-01 -1.1313e-01 -1.8779e-01\n",
       "  1.2379e-01  2.7645e-01 -5.8429e-02  ...  -8.2195e-02 -9.7530e-02 -2.2976e-01\n",
       " -8.8876e-04  5.0248e-01  1.8993e-03  ...   1.9689e-01 -1.1314e-01 -1.8778e-01\n",
       "\n",
       "( 1 ,.,.) = \n",
       " -1.0946e-02  1.3321e-01  1.0045e-01  ...   2.7296e-03  1.3434e-01  8.4473e-02\n",
       "  2.0708e-01  2.6728e-01  2.3116e-01  ...  -2.5411e-01 -1.5995e-01  4.0877e-02\n",
       "  3.0244e-01 -9.9020e-02  2.0334e-01  ...   1.6241e-01  6.0920e-02  5.0653e-02\n",
       "                 ...                   ⋱                   ...                \n",
       "  2.5592e-01  3.9311e-01  5.0377e-02  ...  -1.3236e-01 -1.8280e-01 -2.6516e-02\n",
       "  1.0919e-01 -1.0329e-01  1.5221e-02  ...   4.6337e-01  2.6335e-01 -8.4571e-03\n",
       "  2.5592e-01  3.9311e-01  5.0384e-02  ...  -1.3236e-01 -1.8280e-01 -2.6517e-02\n",
       "\n",
       "( 2 ,.,.) = \n",
       " -1.3506e-02  1.8919e-02 -2.7662e-01  ...  -2.2939e-05  1.1320e-01 -1.9894e-02\n",
       " -1.9670e-02  1.5697e-02  2.8031e-01  ...  -5.2852e-03  3.4669e-02 -8.0836e-03\n",
       "  2.7417e-01  4.9703e-02 -5.9635e-02  ...  -1.6994e-01  2.6134e-02  5.9547e-02\n",
       "                 ...                   ⋱                   ...                \n",
       " -1.2683e-02  9.9504e-02  2.3882e-01  ...   3.6114e-02  8.0330e-03 -4.3641e-02\n",
       "  7.1064e-02  3.5352e-02  9.9182e-02  ...  -7.6258e-02 -2.5753e-02 -2.3143e-01\n",
       " -1.2684e-02  9.9502e-02  2.3882e-01  ...   3.6116e-02  8.0326e-03 -4.3641e-02\n",
       "... \n",
       "\n",
       "(497,.,.) = \n",
       " -1.2724e+00  1.1812e-02  2.1434e-01  ...  -1.5877e+00  1.4116e-01 -7.1643e-01\n",
       " -2.6976e-01 -1.3152e-01  4.7651e-02  ...  -9.0299e-01 -1.3773e-01 -6.5785e-01\n",
       " -7.6247e-02 -8.3714e-02  1.2482e-02  ...  -6.9615e-01 -4.6512e-02 -5.2122e-01\n",
       "                 ...                   ⋱                   ...                \n",
       "  7.4698e-02  1.5441e-01  4.6441e-02  ...  -9.1056e-01 -7.5359e-02 -5.1802e-01\n",
       "  1.2235e-01 -2.6785e-02  4.4897e-02  ...  -8.6391e-01 -1.1627e-01 -8.8432e-01\n",
       "  7.4643e-02  1.5451e-01  4.6433e-02  ...  -9.1067e-01 -7.5415e-02 -5.1806e-01\n",
       "\n",
       "(498,.,.) = \n",
       "  3.4441e-01 -5.8520e-01  2.6389e-01  ...  -2.7809e-01 -1.4636e-02  2.0429e-01\n",
       "  9.6824e-02 -6.2844e-01 -4.3915e-01  ...  -2.8140e-03 -6.5848e-01 -1.2712e-01\n",
       "  4.5876e-02 -6.4078e-01 -1.2519e-01  ...  -2.0341e-02 -9.0289e-01  6.2045e-02\n",
       "                 ...                   ⋱                   ...                \n",
       " -1.7764e-01 -6.2104e-01 -4.8049e-01  ...  -5.5731e-02 -1.9710e-01 -1.6281e-01\n",
       "  4.9506e-02 -7.0489e-01 -1.4088e-01  ...  -2.8132e-02 -1.4486e-01  3.5610e-01\n",
       " -1.9380e-01 -6.3544e-01 -4.7419e-01  ...  -4.8896e-02 -2.5620e-01 -1.4182e-01\n",
       "\n",
       "(499,.,.) = \n",
       " -1.6301e-01  7.4459e-01 -1.1845e+00  ...   9.1020e-01 -2.0486e-01  6.2551e-03\n",
       "  1.3225e-01  2.3475e-01 -9.9341e-01  ...   1.5458e-01  7.8610e-02 -7.5455e-03\n",
       "  2.2090e-01  1.9040e-01 -6.7500e-01  ...   5.5990e-02 -5.9195e-01  6.5884e-03\n",
       "                 ...                   ⋱                   ...                \n",
       " -2.1479e-01  1.2496e-01 -1.3157e+00  ...   6.4412e-02  1.5677e+00  8.9462e-02\n",
       " -5.7811e-02  2.0875e-01 -1.1223e+00  ...  -2.9195e-01 -1.7613e+00  2.0606e-01\n",
       " -2.1427e-01  1.2491e-01 -1.3157e+00  ...   6.4295e-02  1.5677e+00  8.9515e-02\n",
       "[torch.cuda.FloatTensor of size 500x100x128 (GPU 0)]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack(outputs,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
