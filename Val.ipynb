{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim,nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from models.data_loader import DataLoader\n",
    "from models.retain_bidirectional import RETAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "batch_size = 50\n",
    "max_seq_length = 300\n",
    "min_seq_length = 5\n",
    "emb_size = 128\n",
    "hid_size = 128\n",
    "num_classes = 267+1\n",
    "cuda_flag = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/home/a/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loader\n",
    "D = DataLoader(batch_size=batch_size,\n",
    "   data_dir='data/batches/',\n",
    "    mode='val', max_seq_length=max_seq_length, min_seq_length=min_seq_length)\n",
    "\n",
    "# load model\n",
    "model = RETAIN(emb_size,hid_size,num_classes,cuda_flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mjc/github/EHRVis/models/retain_bidirectional.py:35: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greately increasing memory usage. To compact weights again call flatten_parameters().\n",
      "  outputs1 = self.RNN1(embedded) # [b x seq x 128*2]\n",
      "/home/mjc/github/EHRVis/models/retain_bidirectional.py:43: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greately increasing memory usage. To compact weights again call flatten_parameters().\n",
      "  outputs2 = self.RNN2(embedded) # [b x seq x 128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retain_bi_14500.pth\n",
      "Top-1 accuracy: 13400/37411 = 0.358\n",
      "Top-5 accuracy: 25950/37411 = 0.694\n",
      "retain_bi_15000.pth\n",
      "Top-1 accuracy: 13400/37411 = 0.358\n",
      "Top-5 accuracy: 25950/37411 = 0.694\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for num in np.arange(14500,17000,500):\n",
    "    ver = 'retain_bi_%d.pth'%num\n",
    "    model.load_state_dict(torch.load(os.path.join('/home/mjc/github/EHRVis/data/saved_weights',ver)))\n",
    "    model.eval()\n",
    "    # test model\n",
    "    cnt = 0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    correct_5 = 0\n",
    "    for i,file in enumerate(D.val_list):\n",
    "    # for i,file in enumerate(['2014_42.pckl']):\n",
    "    #     print('[%d/%d] opening from %s'%(i+1,len(D.test_list),file))\n",
    "        file_num = int(file.split('_')[1].split('.')[0])\n",
    "        D.batch_size = int(20000/file_num)\n",
    "        D.load_batch_file(file)\n",
    "        for i in range(D.batch_count):\n",
    "            cnt+=1\n",
    "            input_list, targets = D.get_batch()\n",
    "            inputs = model.list_to_tensor(input_list)\n",
    "            outputs = model(inputs)\n",
    "            targets = torch.LongTensor(targets).view(len(inputs),-1)[:,-1] # to only use last of each sequence\n",
    "            if cuda_flag:\n",
    "                targets = targets.cuda()\n",
    "            total+=len(inputs)\n",
    "            targets = targets.tolist()\n",
    "            for tup in zip(targets,outputs.topk(5)[1].data.tolist()):\n",
    "                if tup[0]==tup[1][0]:\n",
    "                    correct +=1\n",
    "                if tup[0] in tup[1]:\n",
    "                    correct_5 +=1\n",
    "    print(ver)\n",
    "    print(\"Top-1 accuracy: %d/%d = %1.3f\"%(correct,total,correct*1.0/total))\n",
    "    print(\"Top-5 accuracy: %d/%d = %1.3f\"%(correct_5,total,correct_5*1.0/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
